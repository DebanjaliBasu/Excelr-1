{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create your first MLP in Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "# load pima indians dataset\n",
    "dataset = numpy.loadtxt(\"/Users/halders/Documents/Excelr/dataset/pima-indians-diabetes.data.csv\", delimiter=\",\")\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(8, kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4126 - accuracy: 0.8093 - val_loss: 0.5525 - val_accuracy: 0.7795\n",
      "Epoch 2/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4240 - accuracy: 0.7879 - val_loss: 0.5405 - val_accuracy: 0.7835\n",
      "Epoch 3/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4245 - accuracy: 0.7977 - val_loss: 0.5669 - val_accuracy: 0.7756\n",
      "Epoch 4/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4314 - accuracy: 0.7899 - val_loss: 0.5492 - val_accuracy: 0.7717\n",
      "Epoch 5/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4138 - accuracy: 0.7899 - val_loss: 0.5501 - val_accuracy: 0.7795\n",
      "Epoch 6/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4259 - accuracy: 0.7899 - val_loss: 0.5467 - val_accuracy: 0.7874\n",
      "Epoch 7/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4156 - accuracy: 0.7938 - val_loss: 0.5421 - val_accuracy: 0.7795\n",
      "Epoch 8/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4082 - accuracy: 0.7957 - val_loss: 0.5647 - val_accuracy: 0.7835\n",
      "Epoch 9/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4192 - accuracy: 0.7938 - val_loss: 0.5432 - val_accuracy: 0.7717\n",
      "Epoch 10/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4156 - accuracy: 0.8016 - val_loss: 0.5409 - val_accuracy: 0.7795\n",
      "Epoch 11/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4140 - accuracy: 0.7899 - val_loss: 0.5648 - val_accuracy: 0.7677\n",
      "Epoch 12/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4206 - accuracy: 0.7938 - val_loss: 0.5374 - val_accuracy: 0.7795\n",
      "Epoch 13/300\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4106 - accuracy: 0.7918 - val_loss: 0.5678 - val_accuracy: 0.7717\n",
      "Epoch 14/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4181 - accuracy: 0.8035 - val_loss: 0.5991 - val_accuracy: 0.7559\n",
      "Epoch 15/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4448 - accuracy: 0.7782 - val_loss: 0.5476 - val_accuracy: 0.7756\n",
      "Epoch 16/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4227 - accuracy: 0.7996 - val_loss: 0.5458 - val_accuracy: 0.7717\n",
      "Epoch 17/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4172 - accuracy: 0.7938 - val_loss: 0.5655 - val_accuracy: 0.7835\n",
      "Epoch 18/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4162 - accuracy: 0.7879 - val_loss: 0.5740 - val_accuracy: 0.7756\n",
      "Epoch 19/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4216 - accuracy: 0.8016 - val_loss: 0.5433 - val_accuracy: 0.7835\n",
      "Epoch 20/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4125 - accuracy: 0.8035 - val_loss: 0.5649 - val_accuracy: 0.7677\n",
      "Epoch 21/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4341 - accuracy: 0.7879 - val_loss: 0.5592 - val_accuracy: 0.7874\n",
      "Epoch 22/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4220 - accuracy: 0.7840 - val_loss: 0.5894 - val_accuracy: 0.7913\n",
      "Epoch 23/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4299 - accuracy: 0.7763 - val_loss: 0.5474 - val_accuracy: 0.7795\n",
      "Epoch 24/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4168 - accuracy: 0.7860 - val_loss: 0.5572 - val_accuracy: 0.7835\n",
      "Epoch 25/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4212 - accuracy: 0.7938 - val_loss: 0.5892 - val_accuracy: 0.7835\n",
      "Epoch 26/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4164 - accuracy: 0.7840 - val_loss: 0.5591 - val_accuracy: 0.7795\n",
      "Epoch 27/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4231 - accuracy: 0.7802 - val_loss: 0.5516 - val_accuracy: 0.7835\n",
      "Epoch 28/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4234 - accuracy: 0.7918 - val_loss: 0.5647 - val_accuracy: 0.7795\n",
      "Epoch 29/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4196 - accuracy: 0.7840 - val_loss: 0.5506 - val_accuracy: 0.7756\n",
      "Epoch 30/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4247 - accuracy: 0.7938 - val_loss: 0.5441 - val_accuracy: 0.7835\n",
      "Epoch 31/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.7977 - val_loss: 0.5449 - val_accuracy: 0.7913\n",
      "Epoch 32/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4311 - accuracy: 0.7860 - val_loss: 0.5524 - val_accuracy: 0.7677\n",
      "Epoch 33/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4328 - accuracy: 0.7860 - val_loss: 0.5404 - val_accuracy: 0.7795\n",
      "Epoch 34/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4186 - accuracy: 0.8016 - val_loss: 0.5414 - val_accuracy: 0.7835\n",
      "Epoch 35/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4183 - accuracy: 0.7860 - val_loss: 0.5551 - val_accuracy: 0.7795\n",
      "Epoch 36/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4190 - accuracy: 0.7860 - val_loss: 0.5437 - val_accuracy: 0.7835\n",
      "Epoch 37/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4309 - accuracy: 0.7782 - val_loss: 0.5527 - val_accuracy: 0.7717\n",
      "Epoch 38/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4167 - accuracy: 0.7879 - val_loss: 0.5511 - val_accuracy: 0.7835\n",
      "Epoch 39/300\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4275 - accuracy: 0.7899 - val_loss: 0.5467 - val_accuracy: 0.7913\n",
      "Epoch 40/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4177 - accuracy: 0.7977 - val_loss: 0.5587 - val_accuracy: 0.7677\n",
      "Epoch 41/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4232 - accuracy: 0.7879 - val_loss: 0.5474 - val_accuracy: 0.7795\n",
      "Epoch 42/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4225 - accuracy: 0.7879 - val_loss: 0.5870 - val_accuracy: 0.7795\n",
      "Epoch 43/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4281 - accuracy: 0.7938 - val_loss: 0.5427 - val_accuracy: 0.7795\n",
      "Epoch 44/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4259 - accuracy: 0.7860 - val_loss: 0.5549 - val_accuracy: 0.7677\n",
      "Epoch 45/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4227 - accuracy: 0.8035 - val_loss: 0.5637 - val_accuracy: 0.7638\n",
      "Epoch 46/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4172 - accuracy: 0.7879 - val_loss: 0.5650 - val_accuracy: 0.7756\n",
      "Epoch 47/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4228 - accuracy: 0.7840 - val_loss: 0.5427 - val_accuracy: 0.7717\n",
      "Epoch 48/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4119 - accuracy: 0.7957 - val_loss: 0.5441 - val_accuracy: 0.7795\n",
      "Epoch 49/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4176 - accuracy: 0.8016 - val_loss: 0.5637 - val_accuracy: 0.7874\n",
      "Epoch 50/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4170 - accuracy: 0.7938 - val_loss: 0.5648 - val_accuracy: 0.7953\n",
      "Epoch 51/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4173 - accuracy: 0.7938 - val_loss: 0.5708 - val_accuracy: 0.7717\n",
      "Epoch 52/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4187 - accuracy: 0.7977 - val_loss: 0.5613 - val_accuracy: 0.7795\n",
      "Epoch 53/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4163 - accuracy: 0.7879 - val_loss: 0.5506 - val_accuracy: 0.7756\n",
      "Epoch 54/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4161 - accuracy: 0.8035 - val_loss: 0.5550 - val_accuracy: 0.7795\n",
      "Epoch 55/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4161 - accuracy: 0.8054 - val_loss: 0.5575 - val_accuracy: 0.7835\n",
      "Epoch 56/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4203 - accuracy: 0.7879 - val_loss: 0.5664 - val_accuracy: 0.7559\n",
      "Epoch 57/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4186 - accuracy: 0.7840 - val_loss: 0.5682 - val_accuracy: 0.7756\n",
      "Epoch 58/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4164 - accuracy: 0.7996 - val_loss: 0.5415 - val_accuracy: 0.7638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4373 - accuracy: 0.7957 - val_loss: 0.6025 - val_accuracy: 0.7677\n",
      "Epoch 60/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.7860 - val_loss: 0.5828 - val_accuracy: 0.7638\n",
      "Epoch 61/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.7860 - val_loss: 0.5439 - val_accuracy: 0.7795\n",
      "Epoch 62/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4249 - accuracy: 0.8035 - val_loss: 0.5648 - val_accuracy: 0.7795\n",
      "Epoch 63/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4180 - accuracy: 0.7918 - val_loss: 0.5548 - val_accuracy: 0.7717\n",
      "Epoch 64/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.7821 - val_loss: 0.5526 - val_accuracy: 0.7717\n",
      "Epoch 65/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4104 - accuracy: 0.8093 - val_loss: 0.5566 - val_accuracy: 0.7835\n",
      "Epoch 66/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4305 - accuracy: 0.7899 - val_loss: 0.5460 - val_accuracy: 0.7874\n",
      "Epoch 67/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4355 - accuracy: 0.7821 - val_loss: 0.5488 - val_accuracy: 0.7756\n",
      "Epoch 68/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4253 - accuracy: 0.7996 - val_loss: 0.5733 - val_accuracy: 0.7717\n",
      "Epoch 69/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4223 - accuracy: 0.7957 - val_loss: 0.5627 - val_accuracy: 0.7756\n",
      "Epoch 70/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4234 - accuracy: 0.7899 - val_loss: 0.5759 - val_accuracy: 0.7598\n",
      "Epoch 71/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4251 - accuracy: 0.7899 - val_loss: 0.5433 - val_accuracy: 0.7717\n",
      "Epoch 72/300\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4104 - accuracy: 0.7821 - val_loss: 0.5599 - val_accuracy: 0.7717\n",
      "Epoch 73/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4237 - accuracy: 0.7957 - val_loss: 0.5689 - val_accuracy: 0.7756\n",
      "Epoch 74/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4166 - accuracy: 0.8093 - val_loss: 0.5787 - val_accuracy: 0.7717\n",
      "Epoch 75/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4198 - accuracy: 0.7996 - val_loss: 0.5519 - val_accuracy: 0.7677\n",
      "Epoch 76/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4184 - accuracy: 0.7899 - val_loss: 0.5356 - val_accuracy: 0.7756\n",
      "Epoch 77/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4258 - accuracy: 0.7782 - val_loss: 0.5461 - val_accuracy: 0.7835\n",
      "Epoch 78/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4177 - accuracy: 0.8054 - val_loss: 0.5628 - val_accuracy: 0.7756\n",
      "Epoch 79/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4107 - accuracy: 0.7938 - val_loss: 0.5481 - val_accuracy: 0.7953\n",
      "Epoch 80/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4161 - accuracy: 0.7899 - val_loss: 0.5755 - val_accuracy: 0.7835\n",
      "Epoch 81/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4251 - accuracy: 0.8035 - val_loss: 0.5641 - val_accuracy: 0.7795\n",
      "Epoch 82/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4262 - accuracy: 0.7918 - val_loss: 0.5584 - val_accuracy: 0.7677\n",
      "Epoch 83/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4142 - accuracy: 0.7957 - val_loss: 0.5635 - val_accuracy: 0.7756\n",
      "Epoch 84/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4180 - accuracy: 0.7938 - val_loss: 0.5570 - val_accuracy: 0.7795\n",
      "Epoch 85/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4191 - accuracy: 0.7957 - val_loss: 0.5495 - val_accuracy: 0.7677\n",
      "Epoch 86/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4082 - accuracy: 0.7918 - val_loss: 0.5598 - val_accuracy: 0.7756\n",
      "Epoch 87/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4136 - accuracy: 0.7938 - val_loss: 0.5420 - val_accuracy: 0.7874\n",
      "Epoch 88/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4153 - accuracy: 0.8074 - val_loss: 0.5525 - val_accuracy: 0.7756\n",
      "Epoch 89/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4184 - accuracy: 0.7957 - val_loss: 0.5586 - val_accuracy: 0.7677\n",
      "Epoch 90/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.7938 - val_loss: 0.5593 - val_accuracy: 0.7795\n",
      "Epoch 91/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4141 - accuracy: 0.7899 - val_loss: 0.5684 - val_accuracy: 0.7717\n",
      "Epoch 92/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4144 - accuracy: 0.7860 - val_loss: 0.5593 - val_accuracy: 0.7795\n",
      "Epoch 93/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4201 - accuracy: 0.7938 - val_loss: 0.5547 - val_accuracy: 0.7756\n",
      "Epoch 94/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4189 - accuracy: 0.8113 - val_loss: 0.5661 - val_accuracy: 0.7874\n",
      "Epoch 95/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4174 - accuracy: 0.7879 - val_loss: 0.5677 - val_accuracy: 0.7795\n",
      "Epoch 96/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4155 - accuracy: 0.7957 - val_loss: 0.5623 - val_accuracy: 0.7756\n",
      "Epoch 97/300\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4213 - accuracy: 0.7918 - val_loss: 0.5631 - val_accuracy: 0.7756\n",
      "Epoch 98/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4211 - accuracy: 0.8016 - val_loss: 0.5626 - val_accuracy: 0.7756\n",
      "Epoch 99/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4286 - accuracy: 0.7821 - val_loss: 0.5509 - val_accuracy: 0.7795\n",
      "Epoch 100/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4181 - accuracy: 0.8035 - val_loss: 0.5497 - val_accuracy: 0.7835\n",
      "Epoch 101/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4187 - accuracy: 0.7879 - val_loss: 0.5516 - val_accuracy: 0.7756\n",
      "Epoch 102/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4113 - accuracy: 0.8054 - val_loss: 0.5903 - val_accuracy: 0.7598\n",
      "Epoch 103/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4191 - accuracy: 0.8035 - val_loss: 0.5622 - val_accuracy: 0.7795\n",
      "Epoch 104/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4167 - accuracy: 0.8113 - val_loss: 0.5609 - val_accuracy: 0.7677\n",
      "Epoch 105/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4194 - accuracy: 0.7938 - val_loss: 0.5459 - val_accuracy: 0.7795\n",
      "Epoch 106/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4372 - accuracy: 0.7860 - val_loss: 0.5606 - val_accuracy: 0.7835\n",
      "Epoch 107/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4168 - accuracy: 0.8016 - val_loss: 0.5538 - val_accuracy: 0.7795\n",
      "Epoch 108/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4178 - accuracy: 0.7957 - val_loss: 0.5537 - val_accuracy: 0.7756\n",
      "Epoch 109/300\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4262 - accuracy: 0.7899 - val_loss: 0.5645 - val_accuracy: 0.7677\n",
      "Epoch 110/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4114 - accuracy: 0.8035 - val_loss: 0.5582 - val_accuracy: 0.7717\n",
      "Epoch 111/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4356 - accuracy: 0.7879 - val_loss: 0.5552 - val_accuracy: 0.7835\n",
      "Epoch 112/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4220 - accuracy: 0.8035 - val_loss: 0.5812 - val_accuracy: 0.7677\n",
      "Epoch 113/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4232 - accuracy: 0.7977 - val_loss: 0.5529 - val_accuracy: 0.7795\n",
      "Epoch 114/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4065 - accuracy: 0.7996 - val_loss: 0.5477 - val_accuracy: 0.7795\n",
      "Epoch 115/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4133 - accuracy: 0.8016 - val_loss: 0.5722 - val_accuracy: 0.7756\n",
      "Epoch 116/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4348 - accuracy: 0.7860 - val_loss: 0.5689 - val_accuracy: 0.7795\n",
      "Epoch 117/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.7977 - val_loss: 0.5708 - val_accuracy: 0.7598\n",
      "Epoch 118/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4239 - accuracy: 0.8016 - val_loss: 0.5781 - val_accuracy: 0.7677\n",
      "Epoch 119/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4290 - accuracy: 0.7840 - val_loss: 0.5619 - val_accuracy: 0.7756\n",
      "Epoch 120/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4138 - accuracy: 0.7899 - val_loss: 0.5537 - val_accuracy: 0.7835\n",
      "Epoch 121/300\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.4209 - accuracy: 0.8016 - val_loss: 0.5628 - val_accuracy: 0.7795\n",
      "Epoch 122/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4131 - accuracy: 0.8113 - val_loss: 0.5689 - val_accuracy: 0.7835\n",
      "Epoch 123/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4129 - accuracy: 0.7918 - val_loss: 0.5733 - val_accuracy: 0.7638\n",
      "Epoch 124/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4251 - accuracy: 0.7899 - val_loss: 0.5756 - val_accuracy: 0.7835\n",
      "Epoch 125/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4200 - accuracy: 0.7899 - val_loss: 0.5634 - val_accuracy: 0.7717\n",
      "Epoch 126/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4202 - accuracy: 0.8035 - val_loss: 0.5655 - val_accuracy: 0.7835\n",
      "Epoch 127/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4124 - accuracy: 0.8132 - val_loss: 0.5744 - val_accuracy: 0.7717\n",
      "Epoch 128/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4121 - accuracy: 0.7957 - val_loss: 0.5592 - val_accuracy: 0.7677\n",
      "Epoch 129/300\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4141 - accuracy: 0.7918 - val_loss: 0.5655 - val_accuracy: 0.7717\n",
      "Epoch 130/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4223 - accuracy: 0.7879 - val_loss: 0.5684 - val_accuracy: 0.7795\n",
      "Epoch 131/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4242 - accuracy: 0.7840 - val_loss: 0.5409 - val_accuracy: 0.7717\n",
      "Epoch 132/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4163 - accuracy: 0.7977 - val_loss: 0.5932 - val_accuracy: 0.7520\n",
      "Epoch 133/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4228 - accuracy: 0.7996 - val_loss: 0.5735 - val_accuracy: 0.7756\n",
      "Epoch 134/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4241 - accuracy: 0.7938 - val_loss: 0.5643 - val_accuracy: 0.7756\n",
      "Epoch 135/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4074 - accuracy: 0.8035 - val_loss: 0.5721 - val_accuracy: 0.7598\n",
      "Epoch 136/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4179 - accuracy: 0.7996 - val_loss: 0.5596 - val_accuracy: 0.7756\n",
      "Epoch 137/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4203 - accuracy: 0.7860 - val_loss: 0.5712 - val_accuracy: 0.7795\n",
      "Epoch 138/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4073 - accuracy: 0.7957 - val_loss: 0.5547 - val_accuracy: 0.7795\n",
      "Epoch 139/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4158 - accuracy: 0.7879 - val_loss: 0.5710 - val_accuracy: 0.7756\n",
      "Epoch 140/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4186 - accuracy: 0.8016 - val_loss: 0.5600 - val_accuracy: 0.7795\n",
      "Epoch 141/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4161 - accuracy: 0.7977 - val_loss: 0.5762 - val_accuracy: 0.7677\n",
      "Epoch 142/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4110 - accuracy: 0.7977 - val_loss: 0.5535 - val_accuracy: 0.7756\n",
      "Epoch 143/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4065 - accuracy: 0.7957 - val_loss: 0.5522 - val_accuracy: 0.7677\n",
      "Epoch 144/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4248 - accuracy: 0.7938 - val_loss: 0.5602 - val_accuracy: 0.7874\n",
      "Epoch 145/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4109 - accuracy: 0.7938 - val_loss: 0.5804 - val_accuracy: 0.7638\n",
      "Epoch 146/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4140 - accuracy: 0.8016 - val_loss: 0.5693 - val_accuracy: 0.7756\n",
      "Epoch 147/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4216 - accuracy: 0.7860 - val_loss: 0.5730 - val_accuracy: 0.7835\n",
      "Epoch 148/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4196 - accuracy: 0.8035 - val_loss: 0.6033 - val_accuracy: 0.7874\n",
      "Epoch 149/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4170 - accuracy: 0.7938 - val_loss: 0.5667 - val_accuracy: 0.7756\n",
      "Epoch 150/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4116 - accuracy: 0.8054 - val_loss: 0.5571 - val_accuracy: 0.7795\n",
      "Epoch 151/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4198 - accuracy: 0.7918 - val_loss: 0.5692 - val_accuracy: 0.7835\n",
      "Epoch 152/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4074 - accuracy: 0.7977 - val_loss: 0.5602 - val_accuracy: 0.7717\n",
      "Epoch 153/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4253 - accuracy: 0.7918 - val_loss: 0.5694 - val_accuracy: 0.7795\n",
      "Epoch 154/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4318 - accuracy: 0.7899 - val_loss: 0.5423 - val_accuracy: 0.7835\n",
      "Epoch 155/300\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4241 - accuracy: 0.7840 - val_loss: 0.5672 - val_accuracy: 0.7717\n",
      "Epoch 156/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4214 - accuracy: 0.7860 - val_loss: 0.5601 - val_accuracy: 0.7795\n",
      "Epoch 157/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4221 - accuracy: 0.7918 - val_loss: 0.5655 - val_accuracy: 0.7677\n",
      "Epoch 158/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4183 - accuracy: 0.8074 - val_loss: 0.5672 - val_accuracy: 0.7795\n",
      "Epoch 159/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4215 - accuracy: 0.7977 - val_loss: 0.5587 - val_accuracy: 0.7795\n",
      "Epoch 160/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4172 - accuracy: 0.7879 - val_loss: 0.5573 - val_accuracy: 0.7795\n",
      "Epoch 161/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4179 - accuracy: 0.7918 - val_loss: 0.5955 - val_accuracy: 0.7598\n",
      "Epoch 162/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4195 - accuracy: 0.8035 - val_loss: 0.5723 - val_accuracy: 0.7717\n",
      "Epoch 163/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4245 - accuracy: 0.8093 - val_loss: 0.5664 - val_accuracy: 0.7677\n",
      "Epoch 164/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4364 - accuracy: 0.7802 - val_loss: 0.5590 - val_accuracy: 0.7795\n",
      "Epoch 165/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4142 - accuracy: 0.7899 - val_loss: 0.5753 - val_accuracy: 0.7677\n",
      "Epoch 166/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4099 - accuracy: 0.7977 - val_loss: 0.5614 - val_accuracy: 0.7795\n",
      "Epoch 167/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4113 - accuracy: 0.8093 - val_loss: 0.5609 - val_accuracy: 0.7717\n",
      "Epoch 168/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4221 - accuracy: 0.8054 - val_loss: 0.5697 - val_accuracy: 0.7756\n",
      "Epoch 169/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4146 - accuracy: 0.8132 - val_loss: 0.5726 - val_accuracy: 0.7756\n",
      "Epoch 170/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4149 - accuracy: 0.7938 - val_loss: 0.5480 - val_accuracy: 0.7874\n",
      "Epoch 171/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4063 - accuracy: 0.8054 - val_loss: 0.5775 - val_accuracy: 0.7717\n",
      "Epoch 172/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4104 - accuracy: 0.8035 - val_loss: 0.5527 - val_accuracy: 0.7717\n",
      "Epoch 173/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4102 - accuracy: 0.8054 - val_loss: 0.5840 - val_accuracy: 0.7835\n",
      "Epoch 174/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4193 - accuracy: 0.8093 - val_loss: 0.5616 - val_accuracy: 0.7717\n",
      "Epoch 175/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4109 - accuracy: 0.8035 - val_loss: 0.5707 - val_accuracy: 0.7677\n",
      "Epoch 176/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4238 - accuracy: 0.7938 - val_loss: 0.5506 - val_accuracy: 0.7795\n",
      "Epoch 177/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4126 - accuracy: 0.7938 - val_loss: 0.5717 - val_accuracy: 0.7598\n",
      "Epoch 178/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4224 - accuracy: 0.7918 - val_loss: 0.5680 - val_accuracy: 0.7835\n",
      "Epoch 179/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4345 - accuracy: 0.7938 - val_loss: 0.5748 - val_accuracy: 0.7795\n",
      "Epoch 180/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4113 - accuracy: 0.8113 - val_loss: 0.5690 - val_accuracy: 0.7795\n",
      "Epoch 181/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4087 - accuracy: 0.8016 - val_loss: 0.5769 - val_accuracy: 0.7677\n",
      "Epoch 182/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4050 - accuracy: 0.7957 - val_loss: 0.5739 - val_accuracy: 0.7795\n",
      "Epoch 183/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4199 - accuracy: 0.8016 - val_loss: 0.5613 - val_accuracy: 0.7795\n",
      "Epoch 184/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4131 - accuracy: 0.8093 - val_loss: 0.5858 - val_accuracy: 0.7638\n",
      "Epoch 185/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4319 - accuracy: 0.7899 - val_loss: 0.5982 - val_accuracy: 0.7717\n",
      "Epoch 186/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4240 - accuracy: 0.7918 - val_loss: 0.5719 - val_accuracy: 0.7795\n",
      "Epoch 187/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4122 - accuracy: 0.7996 - val_loss: 0.5554 - val_accuracy: 0.7835\n",
      "Epoch 188/300\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4146 - accuracy: 0.8171 - val_loss: 0.5743 - val_accuracy: 0.7638\n",
      "Epoch 189/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4136 - accuracy: 0.8016 - val_loss: 0.5753 - val_accuracy: 0.7756\n",
      "Epoch 190/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4146 - accuracy: 0.8054 - val_loss: 0.5654 - val_accuracy: 0.7677\n",
      "Epoch 191/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4176 - accuracy: 0.8074 - val_loss: 0.5617 - val_accuracy: 0.7795\n",
      "Epoch 192/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4086 - accuracy: 0.7996 - val_loss: 0.5740 - val_accuracy: 0.7835\n",
      "Epoch 193/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4148 - accuracy: 0.8054 - val_loss: 0.5605 - val_accuracy: 0.7835\n",
      "Epoch 194/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4311 - accuracy: 0.7996 - val_loss: 0.5680 - val_accuracy: 0.7835\n",
      "Epoch 195/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4243 - accuracy: 0.7996 - val_loss: 0.5576 - val_accuracy: 0.7756\n",
      "Epoch 196/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4104 - accuracy: 0.7899 - val_loss: 0.5627 - val_accuracy: 0.7677\n",
      "Epoch 197/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4130 - accuracy: 0.7899 - val_loss: 0.5747 - val_accuracy: 0.7835\n",
      "Epoch 198/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4169 - accuracy: 0.8113 - val_loss: 0.5620 - val_accuracy: 0.7874\n",
      "Epoch 199/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4106 - accuracy: 0.7996 - val_loss: 0.5678 - val_accuracy: 0.7874\n",
      "Epoch 200/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4022 - accuracy: 0.8035 - val_loss: 0.5802 - val_accuracy: 0.7677\n",
      "Epoch 201/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4227 - accuracy: 0.7918 - val_loss: 0.5708 - val_accuracy: 0.7677\n",
      "Epoch 202/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4166 - accuracy: 0.8016 - val_loss: 0.5724 - val_accuracy: 0.7913\n",
      "Epoch 203/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4212 - accuracy: 0.7918 - val_loss: 0.5714 - val_accuracy: 0.7717\n",
      "Epoch 204/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4221 - accuracy: 0.7899 - val_loss: 0.5638 - val_accuracy: 0.7717\n",
      "Epoch 205/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4252 - accuracy: 0.7996 - val_loss: 0.5750 - val_accuracy: 0.7756\n",
      "Epoch 206/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4121 - accuracy: 0.8016 - val_loss: 0.5687 - val_accuracy: 0.7756\n",
      "Epoch 207/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4201 - accuracy: 0.7899 - val_loss: 0.5961 - val_accuracy: 0.7598\n",
      "Epoch 208/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4130 - accuracy: 0.7977 - val_loss: 0.5736 - val_accuracy: 0.7677\n",
      "Epoch 209/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4091 - accuracy: 0.7918 - val_loss: 0.5580 - val_accuracy: 0.7717\n",
      "Epoch 210/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4118 - accuracy: 0.7938 - val_loss: 0.5656 - val_accuracy: 0.7795\n",
      "Epoch 211/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3974 - accuracy: 0.7957 - val_loss: 0.5957 - val_accuracy: 0.7638\n",
      "Epoch 212/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4120 - accuracy: 0.7957 - val_loss: 0.5828 - val_accuracy: 0.7677\n",
      "Epoch 213/300\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4175 - accuracy: 0.7996 - val_loss: 0.5674 - val_accuracy: 0.7717\n",
      "Epoch 214/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4167 - accuracy: 0.8016 - val_loss: 0.5637 - val_accuracy: 0.7717\n",
      "Epoch 215/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4104 - accuracy: 0.7918 - val_loss: 0.5610 - val_accuracy: 0.7835\n",
      "Epoch 216/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4204 - accuracy: 0.8016 - val_loss: 0.5721 - val_accuracy: 0.7717\n",
      "Epoch 217/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4185 - accuracy: 0.7918 - val_loss: 0.5637 - val_accuracy: 0.7756\n",
      "Epoch 218/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4161 - accuracy: 0.8074 - val_loss: 0.5710 - val_accuracy: 0.7795\n",
      "Epoch 219/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4094 - accuracy: 0.8054 - val_loss: 0.5645 - val_accuracy: 0.7717\n",
      "Epoch 220/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4251 - accuracy: 0.7938 - val_loss: 0.5744 - val_accuracy: 0.7717\n",
      "Epoch 221/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4132 - accuracy: 0.8035 - val_loss: 0.5791 - val_accuracy: 0.7520\n",
      "Epoch 222/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4154 - accuracy: 0.7899 - val_loss: 0.5627 - val_accuracy: 0.7638\n",
      "Epoch 223/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4194 - accuracy: 0.7840 - val_loss: 0.5697 - val_accuracy: 0.7638\n",
      "Epoch 224/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4178 - accuracy: 0.8074 - val_loss: 0.5758 - val_accuracy: 0.7756\n",
      "Epoch 225/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4118 - accuracy: 0.7957 - val_loss: 0.5685 - val_accuracy: 0.7677\n",
      "Epoch 226/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4327 - accuracy: 0.8054 - val_loss: 0.5864 - val_accuracy: 0.7756\n",
      "Epoch 227/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4063 - accuracy: 0.8054 - val_loss: 0.5841 - val_accuracy: 0.7677\n",
      "Epoch 228/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4113 - accuracy: 0.7938 - val_loss: 0.5712 - val_accuracy: 0.7677\n",
      "Epoch 229/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4230 - accuracy: 0.7899 - val_loss: 0.5842 - val_accuracy: 0.7677\n",
      "Epoch 230/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4190 - accuracy: 0.7879 - val_loss: 0.5756 - val_accuracy: 0.7717\n",
      "Epoch 231/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.7899 - val_loss: 0.5859 - val_accuracy: 0.7677\n",
      "Epoch 232/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4138 - accuracy: 0.8054 - val_loss: 0.5617 - val_accuracy: 0.7795\n",
      "Epoch 233/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4111 - accuracy: 0.8074 - val_loss: 0.5719 - val_accuracy: 0.7756\n",
      "Epoch 234/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4213 - accuracy: 0.7977 - val_loss: 0.5671 - val_accuracy: 0.7795\n",
      "Epoch 235/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4116 - accuracy: 0.7996 - val_loss: 0.5636 - val_accuracy: 0.7677\n",
      "Epoch 236/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4100 - accuracy: 0.7957 - val_loss: 0.5671 - val_accuracy: 0.7795\n",
      "Epoch 237/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4137 - accuracy: 0.7938 - val_loss: 0.5672 - val_accuracy: 0.7717\n",
      "Epoch 238/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4115 - accuracy: 0.7938 - val_loss: 0.5673 - val_accuracy: 0.7717\n",
      "Epoch 239/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4212 - accuracy: 0.7977 - val_loss: 0.5932 - val_accuracy: 0.7559\n",
      "Epoch 240/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4131 - accuracy: 0.8113 - val_loss: 0.5792 - val_accuracy: 0.7795\n",
      "Epoch 241/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4082 - accuracy: 0.7957 - val_loss: 0.5766 - val_accuracy: 0.7756\n",
      "Epoch 242/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4106 - accuracy: 0.7899 - val_loss: 0.5569 - val_accuracy: 0.7756\n",
      "Epoch 243/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4106 - accuracy: 0.8093 - val_loss: 0.6205 - val_accuracy: 0.7559\n",
      "Epoch 244/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4225 - accuracy: 0.7996 - val_loss: 0.5717 - val_accuracy: 0.7756\n",
      "Epoch 245/300\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4117 - accuracy: 0.8093 - val_loss: 0.5712 - val_accuracy: 0.7717\n",
      "Epoch 246/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4096 - accuracy: 0.7938 - val_loss: 0.5864 - val_accuracy: 0.7756\n",
      "Epoch 247/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4065 - accuracy: 0.8074 - val_loss: 0.5718 - val_accuracy: 0.7677\n",
      "Epoch 248/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4050 - accuracy: 0.7977 - val_loss: 0.5885 - val_accuracy: 0.7756\n",
      "Epoch 249/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4132 - accuracy: 0.7938 - val_loss: 0.5714 - val_accuracy: 0.7677\n",
      "Epoch 250/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4113 - accuracy: 0.8054 - val_loss: 0.5874 - val_accuracy: 0.7717\n",
      "Epoch 251/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4057 - accuracy: 0.7996 - val_loss: 0.5693 - val_accuracy: 0.7717\n",
      "Epoch 252/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4100 - accuracy: 0.8035 - val_loss: 0.5731 - val_accuracy: 0.7835\n",
      "Epoch 253/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4172 - accuracy: 0.7879 - val_loss: 0.5770 - val_accuracy: 0.7756\n",
      "Epoch 254/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4142 - accuracy: 0.7957 - val_loss: 0.5977 - val_accuracy: 0.7520\n",
      "Epoch 255/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4159 - accuracy: 0.7996 - val_loss: 0.5717 - val_accuracy: 0.7756\n",
      "Epoch 256/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4121 - accuracy: 0.7977 - val_loss: 0.5772 - val_accuracy: 0.7717\n",
      "Epoch 257/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4195 - accuracy: 0.8054 - val_loss: 0.5722 - val_accuracy: 0.7756\n",
      "Epoch 258/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4188 - accuracy: 0.7977 - val_loss: 0.5924 - val_accuracy: 0.7559\n",
      "Epoch 259/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4075 - accuracy: 0.8093 - val_loss: 0.5575 - val_accuracy: 0.7795\n",
      "Epoch 260/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4215 - accuracy: 0.8035 - val_loss: 0.5843 - val_accuracy: 0.7717\n",
      "Epoch 261/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4212 - accuracy: 0.7840 - val_loss: 0.6000 - val_accuracy: 0.7598\n",
      "Epoch 262/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4366 - accuracy: 0.7918 - val_loss: 0.6014 - val_accuracy: 0.7717\n",
      "Epoch 263/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4286 - accuracy: 0.7977 - val_loss: 0.5777 - val_accuracy: 0.7717\n",
      "Epoch 264/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4151 - accuracy: 0.7899 - val_loss: 0.5748 - val_accuracy: 0.7874\n",
      "Epoch 265/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4064 - accuracy: 0.8054 - val_loss: 0.5628 - val_accuracy: 0.7835\n",
      "Epoch 266/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4111 - accuracy: 0.7977 - val_loss: 0.5629 - val_accuracy: 0.7756\n",
      "Epoch 267/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4247 - accuracy: 0.7860 - val_loss: 0.5635 - val_accuracy: 0.7795\n",
      "Epoch 268/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4301 - accuracy: 0.7899 - val_loss: 0.5674 - val_accuracy: 0.7874\n",
      "Epoch 269/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4126 - accuracy: 0.7957 - val_loss: 0.5630 - val_accuracy: 0.7795\n",
      "Epoch 270/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4196 - accuracy: 0.8016 - val_loss: 0.5795 - val_accuracy: 0.7677\n",
      "Epoch 271/300\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4095 - accuracy: 0.7996 - val_loss: 0.5577 - val_accuracy: 0.7874\n",
      "Epoch 272/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4112 - accuracy: 0.7938 - val_loss: 0.5791 - val_accuracy: 0.7756\n",
      "Epoch 273/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4155 - accuracy: 0.7996 - val_loss: 0.5879 - val_accuracy: 0.7598\n",
      "Epoch 274/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4017 - accuracy: 0.7957 - val_loss: 0.5716 - val_accuracy: 0.7677\n",
      "Epoch 275/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4114 - accuracy: 0.7977 - val_loss: 0.5862 - val_accuracy: 0.7559\n",
      "Epoch 276/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3965 - accuracy: 0.8171 - val_loss: 0.5696 - val_accuracy: 0.7677\n",
      "Epoch 277/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4185 - accuracy: 0.7879 - val_loss: 0.5706 - val_accuracy: 0.7756\n",
      "Epoch 278/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4104 - accuracy: 0.7938 - val_loss: 0.5694 - val_accuracy: 0.7717\n",
      "Epoch 279/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4121 - accuracy: 0.7899 - val_loss: 0.5618 - val_accuracy: 0.7717\n",
      "Epoch 280/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4083 - accuracy: 0.8035 - val_loss: 0.5774 - val_accuracy: 0.7677\n",
      "Epoch 281/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4045 - accuracy: 0.8074 - val_loss: 0.5846 - val_accuracy: 0.7795\n",
      "Epoch 282/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4138 - accuracy: 0.8093 - val_loss: 0.5911 - val_accuracy: 0.7638\n",
      "Epoch 283/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4188 - accuracy: 0.8016 - val_loss: 0.5817 - val_accuracy: 0.7638\n",
      "Epoch 284/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4152 - accuracy: 0.7938 - val_loss: 0.5803 - val_accuracy: 0.7717\n",
      "Epoch 285/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4092 - accuracy: 0.7957 - val_loss: 0.5693 - val_accuracy: 0.7874\n",
      "Epoch 286/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4185 - accuracy: 0.8016 - val_loss: 0.5829 - val_accuracy: 0.7835\n",
      "Epoch 287/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4184 - accuracy: 0.8074 - val_loss: 0.5801 - val_accuracy: 0.7638\n",
      "Epoch 288/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4049 - accuracy: 0.7938 - val_loss: 0.5987 - val_accuracy: 0.7756\n",
      "Epoch 289/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4114 - accuracy: 0.7977 - val_loss: 0.5549 - val_accuracy: 0.7756\n",
      "Epoch 290/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.8054 - val_loss: 0.5572 - val_accuracy: 0.7717\n",
      "Epoch 291/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4176 - accuracy: 0.8074 - val_loss: 0.5958 - val_accuracy: 0.7362\n",
      "Epoch 292/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4140 - accuracy: 0.8113 - val_loss: 0.5705 - val_accuracy: 0.7835\n",
      "Epoch 293/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4156 - accuracy: 0.8016 - val_loss: 0.5554 - val_accuracy: 0.7717\n",
      "Epoch 294/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4036 - accuracy: 0.7996 - val_loss: 0.5730 - val_accuracy: 0.7717\n",
      "Epoch 295/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4100 - accuracy: 0.7977 - val_loss: 0.5842 - val_accuracy: 0.7717\n",
      "Epoch 296/300\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4217 - accuracy: 0.8035 - val_loss: 0.5692 - val_accuracy: 0.7795\n",
      "Epoch 297/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4228 - accuracy: 0.7938 - val_loss: 0.5869 - val_accuracy: 0.7638\n",
      "Epoch 298/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4088 - accuracy: 0.8016 - val_loss: 0.5745 - val_accuracy: 0.7638\n",
      "Epoch 299/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4206 - accuracy: 0.7918 - val_loss: 0.5823 - val_accuracy: 0.7756\n",
      "Epoch 300/300\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4088 - accuracy: 0.8132 - val_loss: 0.6007 - val_accuracy: 0.7795\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fed65564510>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(X, Y, validation_split=0.33, epochs=300, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 1ms/step - loss: 0.4758 - accuracy: 0.7891\n",
      "accuracy: 78.91%\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "scores = model.evaluate(X, Y)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'accuracy']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize training history\n",
    "\n",
    "# list all data in history\n",
    "#model.history.history.keys()\n",
    "model.metrics_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-eaa17ddeef0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# summarize history for accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
